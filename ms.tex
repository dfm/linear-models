% Copyright 2015-2017 Dan Foreman-Mackey and the co-authors listed below.

\documentclass[modern]{rnaastex}

\pdfoutput=1

\usepackage{microtype}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{multirow}
\bibliographystyle{aasjournal}

% ------------------ %
% end of AASTeX mods %
% ------------------ %

% Projects:
\newcommand{\project}[1]{\textsf{#1}}
\newcommand{\kepler}{\project{Kepler}}
\newcommand{\lsst}{\project{LSST}}
\newcommand{\tess}{\project{TESS}}
\newcommand{\celerite}{\project{celerite}}
\newcommand{\celeriteterm}{\emph{celerite}}
\newcommand{\emcee}{\project{emcee}}

\newcommand{\foreign}[1]{\emph{#1}}
\newcommand{\etal}{\foreign{et\,al.}}
\newcommand{\etc}{\foreign{etc.}}
\newcommand{\ie}{\foreign{i.e.}}

\newcommand{\figureref}[1]{\ref{fig:#1}}
\newcommand{\Figure}[1]{Figure~\figureref{#1}}
\newcommand{\figurelabel}[1]{\label{fig:#1}}

\newcommand{\Table}[1]{Table~\ref{tab:#1}}
\newcommand{\tablelabel}[1]{\label{tab:#1}}

\renewcommand{\eqref}[1]{\ref{eq:#1}}
\newcommand{\Eq}[1]{Equation~(\eqref{#1})}
\newcommand{\eq}[1]{\Eq{#1}}
\newcommand{\eqalt}[1]{Equation~\eqref{#1}}
\newcommand{\eqlabel}[1]{\label{eq:#1}}

\newcommand{\sectionname}{Section}
\newcommand{\sectref}[1]{\ref{sect:#1}}
\newcommand{\Sect}[1]{\sectionname~\sectref{#1}}
\newcommand{\sect}[1]{\Sect{#1}}
\newcommand{\sectalt}[1]{\sectref{#1}}
\newcommand{\App}[1]{Appendix~\sectref{#1}}
\newcommand{\app}[1]{\App{#1}}
\newcommand{\sectlabel}[1]{\label{sect:#1}}

\newcommand{\T}{\ensuremath{\mathrm{T}}}
\newcommand{\dd}{\ensuremath{\,\mathrm{d}}}
\newcommand{\unit}[1]{{\ensuremath{\,\mathrm{#1}}}}
\newcommand{\bvec}[1]{{\ensuremath{\boldsymbol{#1}}}}

% TO DOS
\newcommand{\todo}[3]{{\color{#2}\emph{#1}: #3}}
\newcommand{\dfmtodo}[1]{\todo{DFM}{red}{#1}}
\newcommand{\citeme}{{\color{red}(citation needed)}}

\newcommand{\Gaussian}[3]{\ensuremath{\frac{1}{(2\pi)^\frac{#3}{2}|#2|^\frac{1}{2}}
            \exp\left[ -\frac{1}{2}#1^\top #2^{-1} #1 \right]}}

% VECTORS AND MATRICES USED IN THIS PAPER
\newcommand{\Normal}{\ensuremath{\mathcal{N}}}
\newcommand{\mA}{\ensuremath{\bvec{A}}}
\newcommand{\mC}{\ensuremath{\bvec{C}}}
\newcommand{\mS}{\ensuremath{\bvec{\Sigma}}}
\newcommand{\mL}{\ensuremath{\bvec{\Lambda}}}
\newcommand{\vw}{\ensuremath{\bvec{w}}}
\newcommand{\vy}{\ensuremath{\bvec{y}}}
\newcommand{\vt}{\ensuremath{\bvec{\theta}}}
\newcommand{\vm}{\ensuremath{\bvec{\mu}(\bvec{\theta})}}
\newcommand{\vre}{\ensuremath{\bvec{r}}}
\newcommand{\vh}{\ensuremath{\bvec{h}}}
\newcommand{\vk}{\ensuremath{\bvec{k}}}

% \shorttitle{}
% \shortauthors{}
% \submitted{Submitted to \textit{The Astrophysical Journal}}

\begin{document}\raggedbottom\sloppy\sloppypar\frenchspacing

\title{%
    Linear models for systematics and nuisances
}

\author[0000-0002-0296-3826]{Rodrigo Luger}
\affil{Department~of~Astronomy, University~of~Washington, Box 351580, Seattle, WA 98195, USA}

\author[0000-0002-9328-5652]{Daniel Foreman-Mackey}
\affil{Center for Computational Astrophysics, Flatiron Institute, 162 Fifth Ave, New York, NY 10010, USA}

\author[0000-0003-2866-9403]{David W.\ Hogg}
\affil{Center for Computational Astrophysics, Flatiron Institute, 162 Fifth Ave, New York, NY 10010, USA}
\affil{Center for Cosmology and Particle Physics, Department of Physics, New York University, 726 Broadway, New York, NY 10003, USA}
\affil{Center for Data Science, New York University, 60 Fifth Ave, New York, NY 10011, USA}
\affil{Max-Planck-Institut f\"ur Astronomie, K\"onigstuhl 17, D-69117 Heidelberg}

%\section{Outline}

%\begin{itemize}
%\item Lots of places in astronomy where physical models are too complicated:
%      use linear models; examples.
%\item Describe math stuff
%\item Include Gaussian Process
%\item Include nonlinear model like Dan's transit search
%\item Linear models can capture nonlinear processes b/c of flexibility
%\end{itemize}


\section{Introduction}

In many astronomical contexts (for example, stellar time-series, or
high-contrast imaging, or stellar spectroscopy), there is structured
noise caused by systematic
effects in the astronomical source, the atmosphere, the telescope, or
the detector.
Sometimes housekeeping data (meta-data), and often the science data themselves,
can be used as predictors of the systematic noise.
Here we recommend the use of linear models to capture and marginalize
out these nuisances in the data.
The linear model can be used to fit and subtract systematics prior to
investigation of the signals of interest, or it
can be used in a simultaneous fit of the systematics and the signals.
In the best case, the linear model is fit simultaneously but then marginalized
out, leaving nuisance-marginalized likelihood or posterior information
about the signals of interest.
We show that if a Gaussian (or extremely wide) prior is placed on the
amplitudes of the linear components, the marginalization reduces to an
operation in pure linear algebra, that can (often) be made fast.
We illustrate our points with \kepler\ time-series data, where the dominant
systematics for many stars are induced by spacecraft variability;
we show the effectiveness of a data-driven linear model in revealing
hard-to-find signals in complex data.

Throughout the field of astronomy, observations often involve recovering or
fitting features that are small compared to other signals in a dataset.
This is true of searches for exoplanet by transit (cite PDC, DFM, RL),
direct-detection (cite Fergus, LOCI), and radial-velocity  (cite something)
data sets, asteroseismology measurements, supernovae searches, spectroscopy
of stars, and other searches for small or rare signals. In all these cases,
one is able to recover the desired signals by modeling the other uninteresting
(but usually dominant) signals in the dataset, such as detector systematics,
stellar variability, or the effects of seeing.
More often than not, a true physical model of these nuisance signals is either
unknown, too difficult to compute, or dependent on too many (unknown)
parameters. A powerful alternative to physical models are linear models, which
can be fully informed by the data at hand. A linear model $\bvec{m}$ is one
that can be constructed from a linear combination of a set of basis vectors
$\{\bvec{a}_j\}$. In matrix form,
%
\begin{align}
\eqlabel{linearmodel}
\vm = \mA \vw
\end{align}
%
where $\mA$ is the \emph{design matrix}, whose columns are the basis
vectors $\{\bvec{a}_j\}$, and $\vw$ is the vector of weights, one
for each basis vector.

Here are some examples where this is done: \citeme.
\citep{Luger:2017,Luger:2016}

Consider the toy example of searching for exoplanet transits in a stellar
light curve taken from a ground-based telescope in the infrared.
The measurement of the light curve is a complicated function of the telescope
focus, the seeing at the observation sight, the atmospheric airmass, and the
thermal emission from the facility, all of which can be time-variable and
depend on additional variables such as the ambient temperature and humidity
in nonlinear ways. {\color{red} CUT?}

Consider a dataset $\vy$ of $N$ measurements $y_i$ with covariance
matrix $\mC$. 
In the common case of data collected with measurement error $\sigma_i$ on 
individual data points but no correlation across measurements, $\mC$ is a 
diagonal matrix with $\mC_{ij} = \sigma_{i}\delta_{ij}$, although in general
the off-diagonal elements capture the covariance between different
measurements.


\begin{align}
p(\vy | \vt, \vw) &= \Normal(\vy; \vm + \mA \vw, \mC) \nonumber\\
%
p(\vw) &= \Normal(\vw; 0, \mL) \nonumber
\end{align}

\begin{align}
\eqlabel{integral}
p(\vy | \vt) &= \int_{-\infty}^{\infty} p(\vw) p(\vy | \vt, \vw) \dd\vw \nonumber \\
%
             &= \int_{-\infty}^{\infty} \Gaussian{\vw}{\mL}{K} \nonumber\\
             & \quad\quad\quad \times \Gaussian{(\vre - \mA \vw)}{\mC}{N}
               \dd\vw \nonumber \\
%
             &= \frac{1}{(2 \pi)^\frac{K + N}{2} |\mL|^\frac{1}{2} |\mC|^\frac{1}{2}}
                \int_{-\infty}^{\infty} \exp \left[ -\frac{1}{2} z \right] \dd\vw
\end{align}
%
where we have used $\vre = \vy - \vm$ and
%
\begin{align}
\eqlabel{z}
z &= \vw^\top \mL^{-1} \vw + \vre^\top \mC^{-1} \vre -
     2(\mA \vw)^\top \mC^{-1} \vre + (\mA \vw)^\top \mC^{-1} \mA \vw.
\end{align}
%
The integral in \eq{integral} is easier to evaluate if we
complete the square and write:
%
\begin{align}
\eqlabel{z_square}
z &= (\vw - \vh)^\top \mS^{-1} (\vw - \vh) + k,
\end{align}
%
where, by comparison with \eq{z}, it can be shown that
%
\begin{align}
\mS^{-1} &= \mL^{-1} + \mA^\top \mC^{-1} \mA \\
%
\vh &= \bvec{\Sigma}\mA^\top \mC^{-1} \vre \\
%
k &= \vre^\top \left( \mC^{-1} - \mC^{-1} \mA \mS \mA^\top \mC^{-1} \right) \vre.
\end{align}
%
We may thus write
%
\begin{align}
\eqlabel{p(y|t)ugly}
p(\vy | \vt) &= \frac{1}{(2 \pi)^\frac{K + N}{2}
                |\mL|^\frac{1}{2}
                |\mC|^\frac{1}{2}}
                \exp \left[ -\frac{1}{2}k \right]
                \int_{-\infty}^{\infty} \exp
                \left[-\frac{1}{2}(\vw - \vh)^\top \mS^{-1} (\vw - \vh)
                \right] \dd\vw.
\end{align}
%
The integral is that of a Gaussian, which evaluates to 
$(2\pi)^\frac{K}{2}|\bvec{\Sigma}|^\frac{1}{2}$. 
By the Matrix Determinant Lemma \citeme, 
%
\begin{align}
|\mS| = {|\mS^{-1}|}^{-1} = \frac{|\mL| |\mC|}{|\mC + \mA \mL \mA^\top|}.
\end{align}
%
%
Additionally, by the Woodbury Identity \citeme,
%
\begin{align}
k &= \vre^\top \left( \mC + \mA \mL \mA^\top \right)^{-1} \vre.
\end{align}
%
Combining these results, the expression in \eq{p(y|t)ugly} therefore simplifies to
\begin{align}
\eqlabel{p(y|t)exp}
p(\vy | \vt) &= \frac{1}{(2 \pi)^\frac{N}{2}
                |\mC + \mA \mL \mA^\top|^\frac{1}{2}} 
                \exp \left[ -\frac{1}{2} \big( \vy - \vm \big)^\top 
                            (\mC + \mA \mL \mA^\top)^{-1} 
                            \big( \vy - \vm \big) 
                     \right].
\end{align}
This is simply the expression for a normal distribution with mean $\vm$ and covariance
$\mC + \mA \mL \mA^\top$:
%
\begin{align}
\eqlabel{p(y|t)normal}
p(\vy | \vt) &= \Normal (\vy; \vm, \mC + \mA \mL \mA^\top).
\end{align}

Note that this is a convolution or correlation. Note that this leads to a simple result.

\acknowledgements
Thank people:
  Patrick Cooper (Duquesne),
  Bernhard Sch\"olkopf (MPI-IS), and
  Dun Wang (NYU).
Don't forget facilities tags.

\bibliography{linear}

\end{document}
